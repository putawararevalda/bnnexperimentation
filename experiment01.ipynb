{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cd2f929",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e206a142",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Revalda Putawara\\.conda\\envs\\bnntest\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c55fb015",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e756eb41",
   "metadata": {},
   "source": [
    "## Defining Model and Loading Model Training Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "354b686e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1ba5152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianCNNSingleFC(PyroModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        prior_mu = 0.\n",
    "        prior_sigma = torch.tensor(10., device=device)\n",
    "\n",
    "        self.conv1 = PyroModule[nn.Conv2d](3, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv1.weight = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([32, 3, 5, 5]).to_event(4))\n",
    "        self.conv1.bias = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([32]).to_event(1))\n",
    "\n",
    "        self.conv2 = PyroModule[nn.Conv2d](32, 64, kernel_size=5, stride=1, padding=2) #initially padding=1 kernel_size=3, without stride\n",
    "        self.conv2.weight = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([64, 32, 5, 5]).to_event(4))\n",
    "        self.conv2.bias = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([64]).to_event(1))\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = PyroModule[nn.Linear](64 * 16 * 16, num_classes)\n",
    "        self.fc1.weight = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([num_classes, 64 * 16 * 16]).to_event(2))\n",
    "        self.fc1.bias = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([num_classes]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc1(x)\n",
    "        \n",
    "        if y is not None:\n",
    "            with pyro.plate(\"data\", x.shape[0]):\n",
    "                pyro.sample(\"obs\", dist.Categorical(logits=logits), obs=y)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e23c29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=54):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3444, 0.3809, 0.4082], std=[0.1809, 0.1331, 0.1137])\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.EuroSAT(root='./data', transform=transform, download=False)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    with open('datasplit/split_indices.pkl', 'rb') as f:\n",
    "        split = pickle.load(f)\n",
    "        train_dataset = Subset(dataset, split['train'])\n",
    "        test_dataset = Subset(dataset, split['test'])\n",
    "\n",
    "    # Add num_workers and pin_memory for faster data loading\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                             num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                            num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca7abb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data_probs(model, test_loader, num_samples=10):\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_logits = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            logits_mc = torch.zeros(num_samples, images.size(0), model.fc1.out_features).to(device)\n",
    "\n",
    "            for i in range(num_samples):\n",
    "                guide_trace = pyro.poutine.trace(guide).get_trace(images)\n",
    "                replayed_model = pyro.poutine.replay(model, trace=guide_trace)\n",
    "                logits = replayed_model(images)\n",
    "                logits_mc[i] = logits\n",
    "\n",
    "            avg_logits = logits_mc.mean(dim=0)\n",
    "            predictions = torch.argmax(avg_logits, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_logits.extend(avg_logits.cpu().numpy())\n",
    "            all_probs.extend(F.softmax(avg_logits, dim=1).cpu().numpy())\n",
    "\n",
    "    return all_labels, all_predictions, all_logits, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af614eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#instantiate the model\n",
    "num_classes = 10\n",
    "bayesian_model = BayesianCNNSingleFC(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c76d2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a49191d6",
   "metadata": {},
   "source": [
    "## Load Trained Model (Before Bitflip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21630c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoDiagonalNormal.loc: torch.Size([217546])\n",
      "AutoDiagonalNormal.scale: torch.Size([217546])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Revalda Putawara\\AppData\\Local\\Temp\\ipykernel_37048\\3793144763.py:13: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  original_param_store[name] = torch.tensor(value.data, requires_grad=value.requires_grad)\n"
     ]
    }
   ],
   "source": [
    "model_path = 'results_eurosat/bayesian_cnn_model_std10_100_epoch.pth'\n",
    "guide_path = 'results_eurosat/bayesian_cnn_guide_std10_100_epoch_guide.pth'\n",
    "pyro_param_store_path = 'results_eurosat/pyro_param_store_std10_100_epoch.pkl'\n",
    "\n",
    "guide = AutoDiagonalNormal(bayesian_model).to(device)\n",
    "\n",
    "pyro.get_param_store().set_state(torch.load(pyro_param_store_path,weights_only=False))\n",
    "\n",
    "original_param_store = {}\n",
    "\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    print(f\"{name}: {value.shape}\")\n",
    "    original_param_store[name] = torch.tensor(value.data, requires_grad=value.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02f8ee28",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_data(batch_size=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59f4177c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoDiagonalNormal.loc: torch.Size([217546])\n",
      "Parameter containing:\n",
      "tensor([ 3.1483, -2.4763, -1.0711,  ..., -2.4452,  4.6454,  1.5156],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "AutoDiagonalNormal.scale: torch.Size([217546])\n",
      "tensor([0.0454, 0.0385, 0.0440,  ..., 7.7091, 6.1614, 6.6950], device='cuda:0',\n",
      "       grad_fn=<SoftplusBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(f\"{name}: {value.shape}\")\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e37b737",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [00:35<00:00,  2.83it/s]\n"
     ]
    }
   ],
   "source": [
    "all_labels, all_predictions, all_logits, all_probs = predict_data_probs(bayesian_model, test_loader, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0659a368",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7118aa4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from confusion matrix: 74.907407%\n"
     ]
    }
   ],
   "source": [
    "#print accuracy from confusion matrix\n",
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"Accuracy from confusion matrix: {accuracy * 100:.6f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897a621b",
   "metadata": {},
   "source": [
    "## Bitflip Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44851161",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bitflip import bitflip_float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d2b77c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_store = pyro.get_param_store()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec517dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_item(param_store, location_index, new_value):\n",
    "    pyro.get_param_store()[param_store][location_index] = new_value\n",
    "\n",
    "    return pyro.get_param_store()[param_store]\n",
    "\n",
    "def run_seu_autodiagonal_normal(location_index: int, bit_i: int, parameter_name: str=\"loc\"):\n",
    "    \"\"\"Perform a bitflip at index i across every variable in the AutoDiagonalNormal guide\"\"\"\n",
    "\n",
    "    assert bit_i in range(0, 33)\n",
    "    assert parameter_name in [\"loc\", \"scale\"]\n",
    "    assert location_index in range(0, len(pyro.get_param_store()[f\"AutoDiagonalNormal.{parameter_name}\"]))\n",
    "\n",
    "    if parameter_name == \"loc\":\n",
    "        param_store_name = \"AutoDiagonalNormal.loc\"\n",
    "    elif parameter_name == \"scale\":\n",
    "        param_store_name = \"AutoDiagonalNormal.scale\"\n",
    "\n",
    "    bayesian_model.to(device)\n",
    "    bayesian_model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        param_dict = {}\n",
    "\n",
    "        for name, value in pyro.get_param_store().items():\n",
    "            #print(f\"{name}: {value.shape}\")\n",
    "            #print(value)\n",
    "            param_dict[name] = value.cpu().detach().numpy()\n",
    "\n",
    "        tensor_cpu = param_dict[param_store_name]\n",
    "\n",
    "        original_val = tensor_cpu[0]\n",
    "        seu_val = bitflip_float32(original_val, bit_i)\n",
    "\n",
    "\n",
    "        print(f\"Original value: {original_val}, SEU value: {seu_val}\")\n",
    "\n",
    "        # Get the parameter\n",
    "        param = pyro.get_param_store().get_param(param_store_name)\n",
    "\n",
    "        # Modify it safely by creating a new tensor\n",
    "        new_param = param.clone()\n",
    "        new_param[location_index] = seu_val  # New Value\n",
    "\n",
    "        # Update the parameter store\n",
    "        if parameter_name == \"loc\":\n",
    "            pyro.get_param_store().__setitem__(param_store_name, new_param) # 74%\n",
    "            #param_store[param_store_name].data.copy_(change_item(param_store_name, location_index, seu_val)) #25%\n",
    "            #pyro.get_param_store()[param_store_name].data[location_index] = seu_val # 25%\n",
    "        elif parameter_name == \"scale\":\n",
    "            pyro.get_param_store().__setitem__(param_store_name, new_param) #10%\n",
    "            #pyro.get_param_store()[param_store_name].data[location_index] = seu_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456ffa3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "05981ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0454, 0.0385, 0.0440,  ..., 7.7091, 6.1614, 6.6950], device='cuda:0',\n",
       "       grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_store[\"AutoDiagonalNormal.scale\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acd3ff98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 3.1483, -2.4763, -1.0711,  ..., -2.4452,  4.6454,  1.5156],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_store[\"AutoDiagonalNormal.loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13a9da35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original value: 0.04540996998548508, SEU value: 1.5452212068469636e+37\n"
     ]
    }
   ],
   "source": [
    "#run_seu_autodiagonal_normal(location_index= 0, bit_i=2, parameter_name=\"loc\")\n",
    "run_seu_autodiagonal_normal(location_index= 0, bit_i=1, parameter_name=\"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d235f6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#param_store[\"AutoDiagonalNormal.loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aed2f1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 3.1483, -2.4763, -1.0711,  ..., -2.4452,  4.6454,  1.5156],\n",
       "       device='cuda:0', requires_grad=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_store[\"AutoDiagonalNormal.loc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6af62b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.5452e+37, 3.8508e-02, 4.3955e-02,  ..., 7.7091e+00, 6.1614e+00,\n",
       "        6.6950e+00], device='cuda:0', grad_fn=<SoftplusBackward0>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_store[\"AutoDiagonalNormal.scale\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd7f2954",
   "metadata": {},
   "source": [
    "## After Bitflip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56841c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "guide = AutoDiagonalNormal(bayesian_model).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f4247b94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights changed: False\n"
     ]
    }
   ],
   "source": [
    "changed = not torch.equal(pyro.get_param_store()[\"AutoDiagonalNormal.loc\"], #AFTER \n",
    "                          original_param_store[\"AutoDiagonalNormal.loc\"], #BEFORE\n",
    "                          )\n",
    "print(\"Weights changed:\", changed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43a7ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [00:08<00:00, 11.75it/s]\n"
     ]
    }
   ],
   "source": [
    "after_all_labels, after_all_predictions, after_all_logits, after_all_probs = predict_data_probs(bayesian_model, test_loader, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f44a9a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "after_cm = confusion_matrix(after_all_labels, after_all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c9ee1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from confusion matrix: 11.111111%\n"
     ]
    }
   ],
   "source": [
    "after_accuracy = np.trace(after_cm) / np.sum(after_cm)\n",
    "print(f\"Accuracy from confusion matrix: {after_accuracy * 100:.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ccd13496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy difference: -63.796296%\n"
     ]
    }
   ],
   "source": [
    "#print the difference in accuracy\n",
    "print(f\"Accuracy difference: {(after_accuracy - accuracy)*100:.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b700a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnntest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
