{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b1dc5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Revalda Putawara\\.conda\\envs\\bnntest\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "import torch\n",
    "\n",
    "import pickle\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956bc019",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "from pyro.nn import PyroModule, PyroSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8844dbfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b17a3f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianCNNSingleFC(PyroModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        prior_mu = 0.\n",
    "        #prior_sigma = 0.1 #accuracy 13.203704% 2 epochs\n",
    "        #prior_sigma = 1. #accuracy 31% 2 epochs\n",
    "        prior_sigma = torch.tensor(10., device=device) #accuracy 45% 10 epochs\n",
    "        #prior_sigma = 100 #accuracy 21% 10 epochs\n",
    "\n",
    "        self.conv1 = PyroModule[nn.Conv2d](3, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv1.weight = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([32, 3, 5, 5]).to_event(4))\n",
    "        self.conv1.bias = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([32]).to_event(1))\n",
    "\n",
    "        self.conv2 = PyroModule[nn.Conv2d](32, 64, kernel_size=5, stride=1, padding=2) #initially padding=1 kernel_size=3, without stride\n",
    "        self.conv2.weight = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([64, 32, 5, 5]).to_event(4))\n",
    "        self.conv2.bias = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([64]).to_event(1))\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.fc1 = PyroModule[nn.Linear](64 * 16 * 16, num_classes)\n",
    "        self.fc1.weight = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([num_classes, 64 * 16 * 16]).to_event(2))\n",
    "        self.fc1.bias = PyroSample(dist.Normal(prior_mu, prior_sigma).expand([num_classes]).to_event(1))\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc1(x)\n",
    "        \n",
    "        # THIS IS THE MISSING PIECE: Define the likelihood\n",
    "        if y is not None:\n",
    "            with pyro.plate(\"data\", x.shape[0]):\n",
    "                pyro.sample(\"obs\", dist.Categorical(logits=logits), obs=y)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6312bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro\n",
    "import pyro.distributions as dist\n",
    "import pyro.nn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from pyro.nn import PyroModule, PyroParam\n",
    "from torch.distributions import constraints\n",
    "\n",
    "class CustomGuide(PyroModule):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        # conv1 weights and bias\n",
    "        self.conv1_weight_loc = PyroParam(torch.randn(32, 3, 5, 5) * 0.1)\n",
    "        self.conv1_weight_scale = PyroParam(torch.ones(32, 3, 5, 5) * 0.1, constraint=constraints.positive)\n",
    "        self.conv1_bias_loc = PyroParam(torch.randn(32) * 0.1)\n",
    "        self.conv1_bias_scale = PyroParam(torch.ones(32) * 0.1, constraint=constraints.positive)\n",
    "\n",
    "        # conv2 weights and bias\n",
    "        self.conv2_weight_loc = PyroParam(torch.randn(64, 32, 5, 5) * 0.1)\n",
    "        self.conv2_weight_scale = PyroParam(torch.ones(64, 32, 5, 5) * 0.1, constraint=constraints.positive)\n",
    "        self.conv2_bias_loc = PyroParam(torch.randn(64) * 0.1)\n",
    "        self.conv2_bias_scale = PyroParam(torch.ones(64) * 0.1, constraint=constraints.positive)\n",
    "\n",
    "        # fc1 weights and bias\n",
    "        self.fc1_weight_loc = PyroParam(torch.randn(num_classes, 64 * 16 * 16) * 0.1)\n",
    "        self.fc1_weight_scale = PyroParam(torch.ones(num_classes, 64 * 16 * 16) * 0.1, constraint=constraints.positive)\n",
    "        self.fc1_bias_loc = PyroParam(torch.randn(num_classes) * 0.1)\n",
    "        self.fc1_bias_scale = PyroParam(torch.ones(num_classes) * 0.1, constraint=constraints.positive)\n",
    "\n",
    "    def forward(self, x, y=None):\n",
    "        pyro.sample(\"conv1.weight\", dist.Normal(self.conv1_weight_loc, self.conv1_weight_scale).to_event(4))\n",
    "        pyro.sample(\"conv1.bias\", dist.Normal(self.conv1_bias_loc, self.conv1_bias_scale).to_event(1))\n",
    "        pyro.sample(\"conv2.weight\", dist.Normal(self.conv2_weight_loc, self.conv2_weight_scale).to_event(4))\n",
    "        pyro.sample(\"conv2.bias\", dist.Normal(self.conv2_bias_loc, self.conv2_bias_scale).to_event(1))\n",
    "        pyro.sample(\"fc1.weight\", dist.Normal(self.fc1_weight_loc, self.fc1_weight_scale).to_event(2))\n",
    "        pyro.sample(\"fc1.bias\", dist.Normal(self.fc1_bias_loc, self.fc1_bias_scale).to_event(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73578d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=54):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3444, 0.3809, 0.4082], std=[0.1809, 0.1331, 0.1137])\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.EuroSAT(root='./data', transform=transform, download=False)\n",
    "\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    with open('datasplit/split_indices.pkl', 'rb') as f:\n",
    "        split = pickle.load(f)\n",
    "        train_dataset = Subset(dataset, split['train'])\n",
    "        test_dataset = Subset(dataset, split['test'])\n",
    "\n",
    "    # Add num_workers and pin_memory for faster data loading\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, \n",
    "                             num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size,\n",
    "                            num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c65a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "bayesian_model = BayesianCNNSingleFC(num_classes=num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e6ad465",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'results_eurosat/bayesian_cnn_model_std10_cust10_epoch.pth'\n",
    "guide_path = 'results_eurosat/bayesian_cnn_guide_std10_cust10_epoch_guide.pth'\n",
    "pyro_param_store_path = 'results_eurosat/pyro_param_store_std10_cust10_epoch.pkl'\n",
    "\n",
    "#guide = AutoDiagonalNormal(bayesian_model).to(device)\n",
    "guide = CustomGuide(num_classes=num_classes).to(device)\n",
    "#guide.load_state_dict(torch.load(guide_path))\n",
    "\n",
    "pyro.get_param_store().set_state(torch.load(pyro_param_store_path,weights_only=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4520752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_data_probs(model, test_loader, num_samples=10):\n",
    "    model.eval()\n",
    "\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "    all_logits = []\n",
    "    all_probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            logits_mc = torch.zeros(num_samples, images.size(0), model.fc1.out_features).to(device)\n",
    "\n",
    "            for i in range(num_samples):\n",
    "                guide_trace = pyro.poutine.trace(guide).get_trace(images)\n",
    "                replayed_model = pyro.poutine.replay(model, trace=guide_trace)\n",
    "                logits = replayed_model(images)\n",
    "                logits_mc[i] = logits\n",
    "\n",
    "            avg_logits = logits_mc.mean(dim=0)\n",
    "            predictions = torch.argmax(avg_logits, dim=1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predictions.cpu().numpy())\n",
    "            all_logits.extend(avg_logits.cpu().numpy())\n",
    "            all_probs.extend(F.softmax(avg_logits, dim=1).cpu().numpy())\n",
    "\n",
    "    return all_labels, all_predictions, all_logits, all_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67ec052a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all weight mean parameters\n",
    "weight_mean_params = {}\n",
    "param_store = pyro.get_param_store()\n",
    "\n",
    "for name, param in param_store.items():\n",
    "    if 'weight' in name and 'loc' in name:  # 'loc' is the mean parameter in AutoDiagonalNormal\n",
    "        weight_mean_params[name] = param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a710765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_weight_loc: torch.Size([32, 3, 5, 5]) - 0.00356109905987978\n",
      "conv1_weight_scale: torch.Size([32, 3, 5, 5]) - 0.1724870204925537\n",
      "conv1_bias_loc: torch.Size([32]) - 0.7791784405708313\n",
      "conv1_bias_scale: torch.Size([32]) - 0.17147037386894226\n",
      "conv2_weight_loc: torch.Size([64, 32, 5, 5]) - -0.24098685383796692\n",
      "conv2_weight_scale: torch.Size([64, 32, 5, 5]) - 0.9782638549804688\n",
      "conv2_bias_loc: torch.Size([64]) - -0.38410523533821106\n",
      "conv2_bias_scale: torch.Size([64]) - 0.8057948350906372\n",
      "fc1_weight_loc: torch.Size([10, 16384]) - 0.00266614044085145\n",
      "fc1_weight_scale: torch.Size([10, 16384]) - 4.2342424392700195\n",
      "fc1_bias_loc: torch.Size([10]) - 0.04563991725444794\n",
      "fc1_bias_scale: torch.Size([10]) - 0.49544063210487366\n"
     ]
    }
   ],
   "source": [
    "for name, param in param_store.items():\n",
    "    print(f\"{name}: {param.shape} - {param.mean().item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d3e61c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1_weight_loc torch.Size([32, 3, 5, 5])\n",
      "conv1_weight_scale torch.Size([32, 3, 5, 5])\n",
      "conv1_bias_loc torch.Size([32])\n",
      "conv1_bias_scale torch.Size([32])\n",
      "conv2_weight_loc torch.Size([64, 32, 5, 5])\n",
      "conv2_weight_scale torch.Size([64, 32, 5, 5])\n",
      "conv2_bias_loc torch.Size([64])\n",
      "conv2_bias_scale torch.Size([64])\n",
      "fc1_weight_loc torch.Size([10, 16384])\n",
      "fc1_weight_scale torch.Size([10, 16384])\n",
      "fc1_bias_loc torch.Size([10])\n",
      "fc1_bias_scale torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ca51f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = load_data(batch_size=54)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39052a95",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [00:32<00:00,  3.08it/s]\n"
     ]
    }
   ],
   "source": [
    "all_labels, all_predictions, all_logits, all_probs = predict_data_probs(bayesian_model, test_loader, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83db52b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "944ae74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(all_labels, all_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "196a55f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from confusion matrix: 10.240741%\n"
     ]
    }
   ],
   "source": [
    "accuracy = np.trace(cm) / np.sum(cm)\n",
    "print(f\"Accuracy from confusion matrix: {accuracy * 100:.6f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785eb0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnntest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
