{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d59f9c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Subset\n",
    "import torch\n",
    "\n",
    "from bayesian_torch.models.dnn_to_bnn import dnn_to_bnn\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c19f238c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))   # -> (32, 32, 32)\n",
    "        x = self.pool(F.relu(self.conv2(x)))   # -> (64, 16, 16)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "698e2ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size=54):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((64, 64)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.3444, 0.3809, 0.4082], std=[0.1809, 0.1331, 0.1137])\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.EuroSAT(root='./data', transform=transform, download=True)\n",
    "\n",
    "\n",
    "    #train_size = int(0.8 * len(dataset))\n",
    "    #test_size = len(dataset) - train_size\n",
    "    #train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "\n",
    "    with open('datasplit/split_indices.pkl', 'rb') as f:\n",
    "        split = pickle.load(f)\n",
    "        train_dataset = Subset(dataset, split['train'])\n",
    "        test_dataset = Subset(dataset, split['test'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba5b36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd319a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=16384, out_features=128, bias=True)\n",
       "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_cnn = CNN()\n",
    "model_cnn.load_state_dict(torch.load(\"results_eurosat/cnn_model.pth\", map_location=\"cpu\"))\n",
    "model_cnn.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5b87d7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.06%\n"
     ]
    }
   ],
   "source": [
    "train_loader, test_loader = load_data()\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device= \"cpu\"\n",
    "test_acc_cnn = evaluate_model(model_cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6532d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73931420",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decision_threshold = 0.8  # Confidence threshold for known/unknown\n",
    "\n",
    "#bcnn_mean_probs, bcnn_classes, bcnn_confidences, bcnnKnownMask, bcnnUnknownMask = predict_with_indecision(ensemble_predict_reproduce(model_bcnn, input_tensor, n_samples=20, seed=reproduce_seed), alpha=0.8)\n",
    "\n",
    "#bcnn_confidences, bcnn_preds = bcnn_mean_probs.max(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb720f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4689edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_bcnn = CNN()\n",
    "\n",
    "const_bnn_prior_parameters = {\n",
    "    \"prior_mu\": 0.0,\n",
    "    \"prior_sigma\": 1.0,\n",
    "    \"posterior_mu_init\": 0.0,\n",
    "    \"posterior_rho_init\": -3.0,\n",
    "    \"type\": \"Reparameterization\",  # Flipout or Reparameterization\n",
    "    \"moped_enable\": False,  # True to initialize mu/sigma from the pretrained dnn weights\n",
    "    \"moped_delta\": 0.5,\n",
    "    }\n",
    "    \n",
    "dnn_to_bnn(\n",
    "    model_bcnn,\n",
    "    const_bnn_prior_parameters\n",
    ")\n",
    "\n",
    "model_bcnn.load_state_dict(torch.load(\"results_eurosat/bayesian_cnn_model.pth\", map_location=\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01a1474",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_bcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50cbd1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_bcnn(model, loader, reproduce_seed=42):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            pred = output.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c08c1888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f916c290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_evaluate_model_bcnn_ensemble_with_uncertainty(model, \n",
    "                                                           loader, \n",
    "                                                           reproduce_seed=42, \n",
    "                                                           n_samples=20, \n",
    "                                                           alpha=0.8,\n",
    "                                                           accepted_accuracy=0):\n",
    "    \"\"\"Returns mean prediction probabilities over n posterior samples\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    unknown_count = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(loader, desc=\"Evaluating\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            batch_preds = []\n",
    "            for _ in range(n_samples):\n",
    "                output = model(data)  # stochastic forward pass\n",
    "                prob = F.softmax(output, dim=1)\n",
    "                batch_preds.append(prob)\n",
    "            mean_probs = torch.stack(batch_preds).mean(dim=0)  # [batch_size, num_classes]\n",
    "\n",
    "            confidences, pred_classes = mean_probs.max(dim=1)\n",
    "            known_mask = confidences >= alpha\n",
    "            unknown_mask = ~known_mask\n",
    "\n",
    "            correct += (pred_classes == target).sum().item()\n",
    "            total += target.size(0)\n",
    "            unknown_count += unknown_mask.sum().item()\n",
    "\n",
    "        accuracy = 100 * correct / total\n",
    "        indecision = unknown_count / total\n",
    "\n",
    "        accuracy_in_presence_of_indecision = correct / (total - unknown_count) if (total - unknown_count) > 0 else 0\n",
    "\n",
    "        # tolerance measurements\n",
    "        max_accuracy = 1\n",
    "        min_accuracy_for_max_penalty = 0\n",
    "\n",
    "        def compute_tolerance(accuracy, accepted_accuracy, max_accuracy):\n",
    "            if accuracy >= accepted_accuracy:\n",
    "                return max(min(accuracy, max_accuracy) - accepted_accuracy, 0) / (max_accuracy - accepted_accuracy)\n",
    "            else:\n",
    "                return 0\n",
    "            \n",
    "        def compute_penalization(accuracy, accepted_accuracy, min_accuracy_for_max_penalty):\n",
    "            if accuracy >= accepted_accuracy:\n",
    "                return 0\n",
    "            else:\n",
    "                return max(0, min(1, (accepted_accuracy - accuracy) / (accepted_accuracy - min_accuracy_for_max_penalty)))\n",
    "        \n",
    "        tolerance_1 = compute_tolerance(accuracy, accepted_accuracy, max_accuracy)\n",
    "        penalization_1 = compute_penalization(accuracy, accepted_accuracy, min_accuracy_for_max_penalty)\n",
    "\n",
    "        # gamma\n",
    "        accepted_ratio_of_certain = 0.8\n",
    "\n",
    "        tolerance_2 = compute_tolerance(1-indecision, accepted_ratio_of_certain, max_accuracy)\n",
    "        penalization_2 = compute_penalization(1-indecision, accepted_ratio_of_certain, 0.5)\n",
    "\n",
    "        robustness_without_uncertainty = (tolerance_1 - penalization_1) / 2 + 1/2\n",
    "        robustness_with_uncertainty = (tolerance_2 - penalization_2) / 2 + 1/2\n",
    "\n",
    "        effectiveness = (accuracy * (1 - indecision)) / (indecision + 1)\n",
    "\n",
    "        #teta = 0 #minimum accuracy accepted\n",
    "        beta = accepted_accuracy * accepted_ratio_of_certain / (accepted_ratio_of_certain + 2)\n",
    "\n",
    "        augmented_robustness = 0 #TODO\n",
    "\n",
    "        print(f\"Test Ensemble Accuracy: {accuracy:.2f}%\")\n",
    "        print(f\"Indecision Rate: {indecision:.2f}\")\n",
    "        print(f\"Accuracy in presence of indecision: {accuracy_in_presence_of_indecision:.2f}%\")\n",
    "        print(f\"Tolerance: {tolerance_1:.2f}\")\n",
    "        print(f\"Penalization: {penalization_1:.2f}\")\n",
    "        print(f\"Robustness without uncertainty: {robustness_without_uncertainty:.2f}\")\n",
    "        print(f\"Robustness with uncertainty: {robustness_with_uncertainty:.2f}\")\n",
    "        print(f\"Effectiveness: {effectiveness:.2f}\")\n",
    "\n",
    "        return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da9e3852",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_bcnn_ensemble_with_uncertainty(model, loader, device=\"cpu\", n_samples=20, alpha=0.8):\n",
    "    \"\"\"Returns mean prediction probabilities over n posterior samples\"\"\"\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in tqdm(loader, desc=\"Evaluating\"):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            batch_preds = []\n",
    "            for _ in range(n_samples):\n",
    "                output = model(data)  # stochastic forward pass\n",
    "                prob = F.softmax(output, dim=1)\n",
    "                batch_preds.append(prob)\n",
    "            mean_probs = torch.stack(batch_preds).mean(dim=0)  # [batch_size, num_classes]\n",
    "\n",
    "            confidences, pred_classes = mean_probs.max(dim=1)\n",
    "            known_mask = confidences >= alpha\n",
    "            unknown_mask = ~known_mask\n",
    "\n",
    "            correct += (pred_classes == target).sum().item()\n",
    "            total += target.size(0)\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Ensemble Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84c7fc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 61.54%\n"
     ]
    }
   ],
   "source": [
    "test_acc_bcnn = evaluate_model(model_bcnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28491040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 84.06%\n"
     ]
    }
   ],
   "source": [
    "test_acc_cnn = evaluate_model(model_cnn, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c0bc684",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [01:51<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Ensemble Accuracy: 67.63%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc_bcnn_ensemble = evaluate_model_bcnn_ensemble_with_uncertainty(model_bcnn, test_loader, n_samples=20, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "819968c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [01:58<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Ensemble Accuracy: 67.81%\n",
      "Indecision Rate: 0.74\n",
      "Accuracy in presence of indecision: 2.58%\n",
      "Tolerance: 1.00\n",
      "Penalization: 0.00\n",
      "Robustness without uncertainty: 1.00\n",
      "Robustness with uncertainty: 0.00\n",
      "Effectiveness: 10.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc_bcnn_ensemble_complete = complete_evaluate_model_bcnn_ensemble_with_uncertainty(model_bcnn, test_loader, n_samples=20, alpha=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39030dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [02:08<00:00,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Ensemble Accuracy: 67.63%\n",
      "Indecision Rate: 0.74\n",
      "Accuracy in presence of indecision: 2.65%\n",
      "Tolerance: 1.00\n",
      "Penalization: 0.00\n",
      "Robustness without uncertainty: 1.00\n",
      "Robustness with uncertainty: 0.00\n",
      "Effectiveness: 9.90\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_acc_bcnn_ensemble_complete = complete_evaluate_model_bcnn_ensemble_with_uncertainty(model_bcnn, \n",
    "                                                                                         test_loader, \n",
    "                                                                                         n_samples=20, \n",
    "                                                                                         alpha=0.8, \n",
    "                                                                                         accepted_accuracy=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a93cae",
   "metadata": {},
   "source": [
    "# BITFLIP SIMULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "982a02bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d558dcc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flip_bit_in_tensor(tensor, bit_position=1, flip_count=1):\n",
    "    flat = tensor.view(-1)\n",
    "    idx = torch.randint(0, flat.numel(), (flip_count,))\n",
    "    for i in idx:\n",
    "        val = flat[i].item()\n",
    "        int_val = np.frombuffer(np.float32(val).tobytes(), dtype=np.uint32)[0]\n",
    "        flipped = int_val ^ (1 << bit_position)\n",
    "        flipped_val = np.frombuffer(np.uint32(flipped).tobytes(), dtype=np.float32)[0]\n",
    "        flat[i] = torch.tensor(flipped_val)\n",
    "    return tensor\n",
    "\n",
    "def inject_seu_conv_layer(layer, bit_position=10, flip_count=1):\n",
    "    with torch.no_grad():\n",
    "        layer.weight.data = flip_bit_in_tensor(layer.weight.data.clone(), bit_position, flip_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7c7a25c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights changed: True\n",
      "Total absolute difference: 2.0026096990538524e+37\n",
      "Test Accuracy: 15.46%\n",
      "Accuracy difference for CNN after SEU injection: -68.59%\n"
     ]
    }
   ],
   "source": [
    "# position 30 is the biggest\n",
    "original_weights = model_cnn.conv1.weight.data.clone()\n",
    "inject_seu_conv_layer(model_cnn.conv1, bit_position=30, flip_count=1)\n",
    "changed = not torch.equal(model_cnn.conv1.weight.data, original_weights)\n",
    "print(\"Weights changed:\", changed)\n",
    "diff = (model_cnn.conv1.weight.data - original_weights).abs().sum().item()\n",
    "print(\"Total absolute difference:\", diff)\n",
    "test_acc_cnn_seu = evaluate_model(model_cnn, test_loader)\n",
    "with torch.no_grad():\n",
    "    model_cnn.conv1.weight.data.copy_(original_weights)\n",
    "#print the difference of accuracy\n",
    "print(\"Accuracy difference for CNN after SEU injection: {:.2f}%\".format(test_acc_cnn_seu - test_acc_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "577a3717",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inject_seu_mu_kernel(layer, bit_position=30, flip_count=1):\n",
    "    with torch.no_grad():\n",
    "        layer.mu_kernel.data = flip_bit_in_tensor(layer.mu_kernel.data.clone(), bit_position, flip_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d874085c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights changed: True\n",
      "Total absolute difference: 4.840707879838647e+37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 100/100 [02:26<00:00,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Ensemble Accuracy: 12.11%\n",
      "Accuracy difference after SEU injection: -46.07%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# position 30 is the biggest\n",
    "original_weights = model_bcnn.conv1.mu_kernel.data.clone()\n",
    "inject_seu_mu_kernel( model_bcnn.conv1, bit_position=30, flip_count=1)\n",
    "changed = not torch.equal( model_bcnn.conv1.mu_kernel, original_weights)\n",
    "print(\"Weights changed:\", changed)\n",
    "diff = ( model_bcnn.conv1.mu_kernel - original_weights).abs().sum().item()\n",
    "print(\"Total absolute difference:\", diff)\n",
    "test_acc_bcnn_seu = evaluate_model_bcnn_ensemble_with_uncertainty(model_bcnn, test_loader, n_samples=20, alpha=0.8)\n",
    "with torch.no_grad():\n",
    "     model_bcnn.conv1.mu_kernel.copy_(original_weights)\n",
    "#print the difference of accuracy\n",
    "print(\"Accuracy difference after SEU injection: {:.2f}%\".format(test_acc_cnn_seu - test_acc_bcnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "244c9add",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "     model_bcnn.conv1.mu_kernel.copy_(original_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1858e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy difference after SEU injection: 46.07%\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy difference after SEU injection: {:.2f}%\".format(abs(test_acc_bcnn - test_acc_cnn_seu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce7fc7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T_destination', '__annotations__', '__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_apply', '_backward_hooks', '_backward_pre_hooks', '_buffers', '_call_impl', '_compiled_call_impl', '_dnn_to_bnn_flag', '_forward_hooks', '_forward_hooks_always_called', '_forward_hooks_with_kwargs', '_forward_pre_hooks', '_forward_pre_hooks_with_kwargs', '_get_backward_hooks', '_get_backward_pre_hooks', '_get_name', '_is_full_backward_hook', '_load_from_state_dict', '_load_state_dict_post_hooks', '_load_state_dict_pre_hooks', '_maybe_warn_non_full_backward_hook', '_modules', '_named_members', '_non_persistent_buffers_set', '_parameters', '_register_load_state_dict_pre_hook', '_register_state_dict_hook', '_replicate_for_data_parallel', '_save_to_state_dict', '_slow_forward', '_state_dict_hooks', '_state_dict_pre_hooks', '_version', '_wrapped_call_impl', 'add_module', 'apply', 'bfloat16', 'bias', 'buffers', 'call_super_init', 'children', 'compile', 'cpu', 'cuda', 'dilation', 'dnn_to_bnn_flag', 'double', 'dump_patches', 'eps_bias', 'eps_kernel', 'eval', 'extra_repr', 'float', 'forward', 'get_buffer', 'get_extra_state', 'get_parameter', 'get_submodule', 'groups', 'half', 'in_channels', 'init_parameters', 'ipu', 'kernel_size', 'kl_div', 'kl_loss', 'load_state_dict', 'modules', 'mtia', 'mu_bias', 'mu_kernel', 'named_buffers', 'named_children', 'named_modules', 'named_parameters', 'out_channels', 'padding', 'parameters', 'posterior_mu_init', 'posterior_rho_init', 'prepare', 'prior_bias_mu', 'prior_bias_sigma', 'prior_mean', 'prior_variance', 'prior_weight_mu', 'prior_weight_sigma', 'quant_prepare', 'register_backward_hook', 'register_buffer', 'register_forward_hook', 'register_forward_pre_hook', 'register_full_backward_hook', 'register_full_backward_pre_hook', 'register_load_state_dict_post_hook', 'register_load_state_dict_pre_hook', 'register_module', 'register_parameter', 'register_state_dict_post_hook', 'register_state_dict_pre_hook', 'requires_grad_', 'rho_bias', 'rho_kernel', 'set_extra_state', 'set_submodule', 'share_memory', 'state_dict', 'stride', 'to', 'to_empty', 'train', 'training', 'type', 'xpu', 'zero_grad']\n"
     ]
    }
   ],
   "source": [
    "print(dir(model_bcnn.conv1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e95a00d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.05555555555556"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48fd7001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15.462962962962964"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_cnn_seu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7ffbd7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61.53703703703704"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_bcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f6b7bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.11111111111111"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc_bcnn_seu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1305b24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bnntest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
